from airflow import DAG
from datetime import datetime
from airflow.operators.bash_operator import BashOperator
from airflow.operators.python_operator import PythonOperator
with DAG('nineleaps_processing',start_date=datetime(2023,5,18),
         schedule_interval='@daily',catchup=False) as dag:
    def karthick():
        return "call from function"
    print_hello1= BashOperator(
        task_id="print_hello1",
        bash_command='echo "Hello 1"'
    )
    function_call=PythonOperator(
        task_id="function_call",
        python_callable=karthick
    )

    print_hello1 >> function_call



from airflow import DAG
from airflow.operators.bash_operator import BashOperator
from datetime import datetime

dag = DAG(
    dag_id='upload_csv',
    start_date=datetime(2023, 5, 1),  # Specify the start date
    schedule_interval=None              # Set the schedule interval as per your requirements
)

upload_task = BashOperator(
    task_id='upload_csv_task',
    bash_command='cp /path/to/local/file.csv /path/to/destination/file.csv',
    dag=dag
)
